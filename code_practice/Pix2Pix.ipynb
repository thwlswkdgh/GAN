{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch5_Pix2Pix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlgMTxWJu86Al82mlN9U0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thwlswkdgh/GAN/blob/main/code_practice/Pix2Pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FWoFzOEC-8L"
      },
      "source": [
        "Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIiXmuJgocEZ"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Reshape, Input, BatchNormalization, Concatenate\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import UpSampling2D, Convolution2D, MaxPooling2D,Deconvolution2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam,Adamax\n",
        "from keras import initializers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import np_utils\n",
        "class Generator(object):\n",
        "    def __init__(self, width = 28, height= 28, channels = 1):\n",
        "        \n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.SHAPE = (width,height,channels)\n",
        "\n",
        "        self.Generator = self.model()\n",
        "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
        "        self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER,metrics=['accuracy'])\n",
        "\n",
        "        self.save_model()\n",
        "        #self.summary()\n",
        "\n",
        "    def model(self):\n",
        "        input_layer = Input(shape=self.SHAPE)\n",
        "        \n",
        "        down_1 = Convolution2D(64  , kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
        "\n",
        "        down_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(down_1)\n",
        "        norm_2 = BatchNormalization()(down_2)\n",
        "\n",
        "        down_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_2)\n",
        "        norm_3 = BatchNormalization()(down_3)\n",
        "\n",
        "        down_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_3)\n",
        "        norm_4 = BatchNormalization()(down_4)\n",
        "\n",
        "        down_5 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_4)\n",
        "        norm_5 = BatchNormalization()(down_5)\n",
        "\n",
        "        down_6 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_5)\n",
        "        norm_6 = BatchNormalization()(down_6)\n",
        "\n",
        "        down_7 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_6)\n",
        "        norm_7 = BatchNormalization()(down_7)\n",
        "\n",
        "\n",
        "        upsample_1 = UpSampling2D(size=2)(norm_7)\n",
        "        up_conv_1 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_1)\n",
        "        norm_up_1 = BatchNormalization(momentum=0.8)(up_conv_1)\n",
        "        add_skip_1 = Concatenate()([norm_up_1,norm_6])\n",
        "\n",
        "\n",
        "        upsample_2 = UpSampling2D(size=2)(add_skip_1)\n",
        "        up_conv_2 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_2)\n",
        "        norm_up_2 = BatchNormalization(momentum=0.8)(up_conv_2)\n",
        "        add_skip_2 = Concatenate()([norm_up_2,norm_5])\n",
        "\n",
        "        upsample_3 = UpSampling2D(size=2)(add_skip_2)\n",
        "        up_conv_3 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_3)\n",
        "        norm_up_3 = BatchNormalization(momentum=0.8)(up_conv_3)\n",
        "        add_skip_3 = Concatenate()([norm_up_3,norm_4])\n",
        "\n",
        "\n",
        "        upsample_4 = UpSampling2D(size=2)(add_skip_3)\n",
        "        up_conv_4 = Convolution2D(64*4, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_4)\n",
        "        norm_up_4 = BatchNormalization(momentum=0.8)(up_conv_4)\n",
        "        add_skip_4 = Concatenate()([norm_up_4,norm_3])\n",
        "\n",
        "        upsample_5 = UpSampling2D(size=2)(add_skip_4)\n",
        "        up_conv_5 = Convolution2D(64*2, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_5)\n",
        "        norm_up_5 = BatchNormalization(momentum=0.8)(up_conv_5)\n",
        "        add_skip_5 = Concatenate()([norm_up_5,norm_2])\n",
        "\n",
        "        upsample_6 = UpSampling2D(size=2)(add_skip_5)\n",
        "        up_conv_6 = Convolution2D(64, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_6)\n",
        "        norm_up_6 = BatchNormalization(momentum=0.8)(up_conv_6)\n",
        "        add_skip_6 = Concatenate()([norm_up_6,down_1])\n",
        "\n",
        "        last_upsample = UpSampling2D(size=2)(add_skip_6)\n",
        "        output_layer = Convolution2D(self.C, kernel_size=4, strides=1, padding='same',activation='tanh')(last_upsample)\n",
        "        \n",
        "        return Model(input_layer,output_layer)\n",
        "\n",
        "    def summary(self):\n",
        "        return self.Generator.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.Generator, to_file='/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/Generator_Model.png', show_shapes=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRj18yFkC9AC"
      },
      "source": [
        "Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dkv4skxBNWl"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Lambda, Concatenate\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD,Nadam, Adamax\n",
        "import keras.backend as K\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "\n",
        "class Discriminator(object):\n",
        "    def __init__(self, width = 28, height= 28, channels = 1, starting_filters=64):\n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.CAPACITY = width*height*channels\n",
        "        self.SHAPE = (width,height,channels)\n",
        "        self.FS = starting_filters #FilterStart\n",
        "        \n",
        "        self.Discriminator = self.model()\n",
        "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
        "        self.Discriminator.compile(loss='mse', optimizer=self.OPTIMIZER, metrics=['accuracy'] )\n",
        "\n",
        "        self.save_model()\n",
        "        #self.summary()\n",
        "\n",
        "    def model(self):\n",
        "\n",
        "\n",
        "        input_A = Input(shape=self.SHAPE)\n",
        "        input_B = Input(shape=self.SHAPE)\n",
        "        input_layer = Concatenate(axis=-1)([input_A, input_B])\n",
        "\n",
        "        up_layer_1 = Convolution2D(self.FS, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
        "\n",
        "        up_layer_2 = Convolution2D(self.FS*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(up_layer_1)\n",
        "        leaky_layer_2 =  BatchNormalization(momentum=0.8)(up_layer_2)\n",
        "\n",
        "        up_layer_3 = Convolution2D(self.FS*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(leaky_layer_2)\n",
        "        leaky_layer_3 =  BatchNormalization(momentum=0.8)(up_layer_3)\n",
        "\n",
        "        up_layer_4 = Convolution2D(self.FS*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(leaky_layer_3)\n",
        "        leaky_layer_4 = BatchNormalization(momentum=0.8)(up_layer_4)\n",
        "\n",
        "        output_layer = Convolution2D(1, kernel_size=4, strides=1, padding='same')(leaky_layer_4)\n",
        "        \n",
        "        return Model([input_A, input_B],output_layer)\n",
        "\n",
        "    def summary(self):\n",
        "        return self.Discriminator.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.Discriminator, to_file='/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/Discriminator_Model.png', show_shapes=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmyLOYfaDnoP"
      },
      "source": [
        "GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cph5quM_DnE2"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "class GAN(object):\n",
        "    def __init__(self, model_inputs=[],model_outputs=[]):\n",
        "        self.OPTIMIZER = SGD(lr=2e-4,nesterov=True)\n",
        "\n",
        "        self.inputs = model_inputs\n",
        "        self.outputs = model_outputs\n",
        "        self.gan_model = Model(inputs = self.inputs, outputs = self.outputs)\n",
        "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5)\n",
        "        self.gan_model.compile(loss=['mse', 'mae'],\n",
        "                            loss_weights=[  1, 100],\n",
        "                            optimizer=self.OPTIMIZER)\n",
        "        self.save_model()\n",
        "        #self.summary()\n",
        "\n",
        "    def model(self):\n",
        "        model = Model()\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        return self.gan_model.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.gan_model, to_file='/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/GAN_Model.png', show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImiAV2ZNDhMg"
      },
      "source": [
        "Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umIpa67sBNgP"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "#from gan import GAN\n",
        "#from generator import Generator\n",
        "#from discriminator import Discriminator\n",
        "from keras.layers import Input\n",
        "from keras.datasets import mnist\n",
        "from random import randint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, height = 256, width = 256, channels=3, epochs = 50000, batch = 1, checkpoint = 50, train_data_path = '',test_data_path=''):\n",
        "        self.EPOCHS = epochs\n",
        "        self.BATCH = batch\n",
        "        self.H = height\n",
        "        self.W = width\n",
        "        self.C = channels\n",
        "        self.CHECKPOINT = checkpoint\n",
        "\n",
        "        self.X_train_B, self.X_train_A = self.load_data(train_data_path)\n",
        "        self.X_test_B, self.X_test_A  = self.load_data(test_data_path)\n",
        "\n",
        "\n",
        "        self.generator = Generator(height=self.H, width=self.W, channels=self.C)\n",
        "        self.generator.Generator = load_model('/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/generator.h5')\n",
        "\n",
        "        self.orig_A = Input(shape=(self.W, self.H, self.C))\n",
        "        self.orig_B = Input(shape=(self.W, self.H, self.C))\n",
        "\n",
        "        self.fake_A = self.generator.Generator(self.orig_B)\n",
        "\n",
        "        self.discriminator = Discriminator(height=self.H, width=self.W, channels=self.C)\n",
        "        self.discriminator.Discriminator = load_model('/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/discriminator.h5')\n",
        "        self.discriminator.trainable = False\n",
        "        self.valid = self.discriminator.Discriminator([self.fake_A,self.orig_B])\n",
        "        model_inputs  = [self.orig_A,self.orig_B]\n",
        "        model_outputs = [self.valid, self.fake_A]\n",
        "        self.gan = GAN(model_inputs=model_inputs,model_outputs=model_outputs)\n",
        "        self.gan.GAN = ('/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/gan_model.h5')\n",
        "        \n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        listOFFiles = self.grabListOfFiles(data_path,extension=\"jpg\")\n",
        "        imgs_temp = np.array(self.grabArrayOfImages(listOFFiles))\n",
        "        imgs_A = []\n",
        "        imgs_B = []\n",
        "        i = 1;\n",
        "        for img in imgs_temp:\n",
        "            imgs_A.append(img[:,:self.H])\n",
        "            imgs_B.append(img[:,self.H:])\n",
        "\n",
        "        imgs_A_out = self.norm_and_expand(np.array(imgs_A))\n",
        "        imgs_B_out = self.norm_and_expand(np.array(imgs_B))\n",
        "\n",
        "        return imgs_A_out, imgs_B_out\n",
        "\n",
        "    def norm_and_expand(self,arr):\n",
        "        arr = (arr.astype(np.float32) - 127.5)/127.5\n",
        "        normed = np.expand_dims(arr, axis=3)\n",
        "        return normed\n",
        "\n",
        "    def grabListOfFiles(self,startingDirectory,extension=\".webp\"):\n",
        "        listOfFiles = []\n",
        "        for file in os.listdir(startingDirectory):\n",
        "            if file.endswith(extension):\n",
        "                listOfFiles.append(os.path.join(startingDirectory, file))\n",
        "        return listOfFiles\n",
        "\n",
        "    def grabArrayOfImages(self,listOfFiles,gray=False):\n",
        "        imageArr = []\n",
        "        print(\"start grabArrayOfImages\");\n",
        "        for f in listOfFiles:\n",
        "            if gray:\n",
        "                im = Image.open(f).convert(\"L\")\n",
        "            else:\n",
        "                im = Image.open(f).convert(\"RGB\")\n",
        "            imData = np.asarray(im)\n",
        "            imageArr.append(imData)\n",
        "        return imageArr\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        for e in range(self.EPOCHS):\n",
        "            b = 0\n",
        "            X_train_A_temp = deepcopy(self.X_train_A)\n",
        "            X_train_B_temp = deepcopy(self.X_train_B)\n",
        "\n",
        "            number_of_batches = len(self.X_train_A)\n",
        "        \n",
        "            for b in range(number_of_batches):\n",
        "                # Train Discriminator\n",
        "                # Grab Real Images for this training batch\n",
        "                starting_ind = randint(0, (len(X_train_A_temp)-1))\n",
        "                real_images_raw_A = X_train_A_temp[ starting_ind : (starting_ind + 1) ]\n",
        "                real_images_raw_B = X_train_B_temp[ starting_ind : (starting_ind + 1) ]\n",
        "\n",
        "                # Delete the images used until we have none left\n",
        "                X_train_A_temp = np.delete(X_train_A_temp,range(starting_ind,(starting_ind + 1)),0)\n",
        "                X_train_B_temp = np.delete(X_train_B_temp,range(starting_ind,(starting_ind + 1)),0)\n",
        "                \n",
        "\n",
        "                batch_A = real_images_raw_A.reshape( 1, self.W, self.H, self.C )\n",
        "                batch_B = real_images_raw_B.reshape( 1, self.W, self.H, self.C )\n",
        "                #temp_B = real_images_raw_B.reshape(self.W, self.H, self.C )\n",
        "                #plt.imshow(temp_B);\n",
        "\n",
        "                # PatchGAN\n",
        "                y_valid = np.ones((1,)+(int(self.W / 2**4), int(self.W / 2**4), 1))\n",
        "                y_fake = np.zeros((1,)+(int(self.W / 2**4), int(self.W / 2**4), 1))\n",
        "                fake_A = self.generator.Generator.predict(batch_B)\n",
        "                \n",
        "                # Now, train the discriminator with this batch of reals\n",
        "                discriminator_loss_real = self.discriminator.Discriminator.train_on_batch([batch_A,batch_B],y_valid)[0]\n",
        "                discriminator_loss_fake = self.discriminator.Discriminator.train_on_batch([fake_A,batch_B],y_fake)[0]\n",
        "                full_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "                generator_loss = self.gan.gan_model.train_on_batch([batch_A, batch_B],[y_valid,batch_A])    \n",
        "\n",
        "                print ('Batch: '+str(int(b))+', [Full Discriminator :: Loss: '+str(full_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
        "                #if b % self.CHECKPOINT == 0 :\n",
        "                if b % 10 == 0 :\n",
        "                    label = str(e)+'_'+str(b)\n",
        "                    self.plot_checkpoint(label)\n",
        "\n",
        "            print ('Epoch: '+str(int(e))+', [Full Discriminator :: Loss:'+str(full_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
        "            \n",
        "                        \n",
        "        return\n",
        "\n",
        "    def plot_checkpoint(self,b):\n",
        "        orig_filename = \"/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/batch/batch_check_\"+str(b)+\"_original.png\"\n",
        "\n",
        "        r, c = 3, 3\n",
        "        random_inds = random.sample(range(len(self.X_test_A)),3)\n",
        "        imgs_A = self.X_test_A[random_inds].reshape(3, self.W, self.H, self.C )\n",
        "        imgs_B = self.X_test_B[random_inds].reshape( 3, self.W, self.H, self.C )\n",
        "        fake_A = self.generator.Generator.predict(imgs_B)\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Style', 'Generated', 'Original']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[i])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/batch/batch_check_\"+str(b)+\".png\")\n",
        "        plt.close('all')\n",
        "\n",
        "        self.gan.gan_model.save('/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/gan_model.h5')\n",
        "        self.generator.Generator.save('/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/generator.h5')\n",
        "        self.discriminator.Discriminator.save('/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/discriminator.h5')\n",
        "\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-s4Zd1ioeSC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "347df441-6e89-4e13-8b26-c5c2349fc07d"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "#from train import Trainer\n",
        "\n",
        "# Command Line Argument Method\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "HEIGHT  = 256\n",
        "WIDTH   = 256\n",
        "CHANNELS = 3\n",
        "EPOCHS = 100\n",
        "BATCH = 1\n",
        "CHECKPOINT = 50\n",
        "TRAIN_PATH = \"/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/cityscapes/train/\"\n",
        "TEST_PATH = \"/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/cityscapes/val/\"\n",
        "\n",
        "trainer = Trainer(height=HEIGHT,width=WIDTH, channels=CHANNELS,epochs =EPOCHS,\\\n",
        "                 batch=BATCH,\\\n",
        "                 checkpoint=CHECKPOINT,\\\n",
        "                 train_data_path=TRAIN_PATH,\\\n",
        "                 test_data_path=TEST_PATH)\n",
        "\n",
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "start grabArrayOfImages\n",
            "start grabArrayOfImages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, [Full Discriminator :: Loss: 0.30229128897190094], [ Generator :: Loss: [31.443424224853516, 0.0878463089466095, 0.3135557770729065]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-35fd5325d37b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHANNELS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mtrain_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mtest_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-02779ec79d32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', [Full Discriminator :: Loss:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'], [ Generator :: Loss: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-02779ec79d32>\u001b[0m in \u001b[0;36mplot_checkpoint\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/gan_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/generator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/Pix2Pix/out/discriminator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2146\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m   def save_weights(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    144\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    145\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 146\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkPMG33XEDnp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "c7d93619-4a26-416a-b9ac-d2a928f1b46f"
      },
      "source": [
        "imgs_A = Trainer.X_test_A[random_inds].reshape(3, self.W, self.H, self.C )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d3dac3b84237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgs_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Trainer' has no attribute 'X_test_A'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5otg_0FXGrBX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}